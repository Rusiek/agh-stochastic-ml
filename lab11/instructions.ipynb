{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§¬ LLM Ã— Evolutionary Algorithms\n",
    "\n",
    "### Learning objectives\n",
    "- Practical â€” set up an LLM API (Gemini) and call it programmatically from Python.\n",
    "- Technical â€” parse, compile and safely execute code emitted by an LLM.\n",
    "- Research-oriented â€” evaluate LLM-generated meta-heuristics on a standard benchmark and iterate on them with simple evolutionary operators.\n",
    "- Critical thinking â€” assess algorithmic ideas for correctness, novelty and computational efficiency.\n",
    "\n",
    "### 1. Why are we doing this?\n",
    "\n",
    "Modern Large Language Models (LLMs) are powerful tools that extend far beyond chatting. They can generate creative text, translate languages, write different kinds of content, and, importantly for us today, write code. We're going to explore how LLMs can be used to design new algorithms, drawing inspiration from how natural evolution works.\n",
    "\n",
    "### 2. Environment setup\n",
    "- Create / signâ€‘in to [GoogleÂ AIÂ Studio](https://aistudio.google.com/prompts/new_chat).\n",
    "- Generate an API key and copy it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os\n",
    "\n",
    "MODEL = \"gemini-2.0-flash\"\n",
    "\n",
    "client = genai.Client(api_key=\"paste-your-key-here\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL,\n",
    "    contents=[\"Hello, world!\"]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see a greeting, you are good to go! \n",
    "\n",
    "### Why Gemini? \n",
    "We're using the Gemini API because it provides a generous free tier suitable for experimentation (e.g., 1500 free requests per day)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Large Language Models\n",
    "The internal workings of LLMs are complex and beyond today's scope. For our purposes, we can treat an LLM as a sophisticated \"text-to-text\" function. A key strength of modern LLMs is their ability to understand and generate code in various programming languages. We'll leverage this today.\n",
    "\n",
    "\n",
    "Let's start with a simple example:\n",
    "> Problem: You are given a list of integers from 1 to n, with exactly one number missing. Write a Python function to find the missing number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "Problem: You are given a list of integers from 1 to n, with exactly one number missing. \n",
    "Write a Python function to find the missing number.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(model=MODEL, contents=[PROMPT])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good start, but the LLM might return explanatory text along with the code, or the code might not be in a directly usable format. For systematic use, we need more control.\n",
    "\n",
    "To make the LLM's output reliable for our task, we will:\n",
    "1. Force a Specific Function Signature: We'll instruct the LLM to define a function with a name and parameters we choose.\n",
    "2. Parse the Code: We'll extract the Python code from the LLM's response (which is often formatted in Markdown).\n",
    "3. Verify and Execute: We'll compile the extracted code and then test it against predefined test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_WITH_SIGNATURE = \"\"\"\n",
    "Problem: You are given a list of integers from 1 to n, with exactly one number missing. \n",
    "Write a Python function to find the missing number.\n",
    "\n",
    "Your solution should we wrapped in a Markdown Python block code. \n",
    "```python\n",
    "def find_missing_number(numbers: list[int]) -> int:\n",
    "    ...\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(model=MODEL, contents=[PROMPT_WITH_SIGNATURE])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that LLM was able to follow our instructions. Right now we need to parse the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "from typing import Any, Callable\n",
    "\n",
    "\n",
    "class FunctionParser:\n",
    "    @staticmethod\n",
    "    def parse(\n",
    "        model_response: str, function_name: str\n",
    "    ) -> Callable[[list[int]], int] | None:\n",
    "        function_str = FunctionParser.extract_code(model_response)\n",
    "        if not function_str:\n",
    "            print(\"No function found in response\")\n",
    "            return None\n",
    "\n",
    "        if not FunctionParser.validate_function_syntax(function_str):\n",
    "            print(\"Invalid function syntax\")\n",
    "            return None\n",
    "\n",
    "        namespace: dict[str, Any] = {}\n",
    "        # WARNING: This is not safe and should not be used in production\n",
    "        # This should be run in a sandboxed environment\n",
    "        exec(function_str, namespace)\n",
    "        return namespace[function_name]\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_function_syntax(function_str: str) -> bool:\n",
    "        try:\n",
    "            ast.parse(function_str)\n",
    "            return True\n",
    "        except SyntaxError:\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_code(text: str) -> str | None:\n",
    "        pattern = r\"```python\\s*(.*?)\\s*```\"\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        return match.group(1) if match else None\n",
    "\n",
    "\n",
    "function = FunctionParser.parse(response.text, \"find_missing_number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also verify if the result is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert function([1, 3, 4, 5]) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement automatic verification methods, including those that quantify the quality of our function. A simple yet effective metric is the percentage of test cases passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "import random\n",
    "\n",
    "class FunctionVerifier:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sizes: list[int] | None = None,\n",
    "        *,\n",
    "        rng_seed: int | None = None,\n",
    "    ) -> None:\n",
    "        self.sizes = sizes if sizes is not None else [5, 10, 20]\n",
    "        self._rng = random.Random(rng_seed)\n",
    "\n",
    "    def _test_cases(self) -> Generator[tuple[list[int], int], None, None]:\n",
    "        for n in self.sizes:\n",
    "            full = list(range(1, n + 1))\n",
    "            for idx in range(n):\n",
    "                data = full.copy()\n",
    "                missing = data.pop(idx)\n",
    "                self._rng.shuffle(data)\n",
    "                yield data, missing\n",
    "\n",
    "    def verify(\n",
    "        self,\n",
    "        func: Callable[[list[int]], int],\n",
    "    ) -> float:\n",
    "        solved = 0\n",
    "        total = 0\n",
    "\n",
    "        for data, expected in self._test_cases():\n",
    "            try:\n",
    "                result = func(data.copy())\n",
    "                if result == expected:\n",
    "                    solved += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error during test case execution: {e}\")\n",
    "            total += 1\n",
    "\n",
    "        return solved / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "verifier = FunctionVerifier()\n",
    "test_pass_rate = verifier.verify(function)\n",
    "print(f\"Test pass rate: {test_pass_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we've established that LLMs can generate Python functions, and we can programmatically parse and verify their correctness. This forms the foundation for using LLMs in more complex algorithmic tasks, especially when combined with evolutionary approaches!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. LLM Ã— Evolutionary Algorithms\n",
    "\n",
    "How can large language models be leveraged for optimization? One promising direction is to employ LLMs to generate novel optimization algorithms in much the same way they are used to synthesize problem-solving functions. Given that algorithms can be expressed as Python functions, this presents a natural and flexible framework for exploring algorithmic design via language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_METAHEURISTIC = \"\"\"\n",
    "Problem: You are tasked with inventing a novel metaheuristic algorithm capable of minimizing an arbitrary real-valued, \n",
    "black-box, single-objective function defined over simple bound constraints.\n",
    "\n",
    "Write a Python function that implements your algorithm. The function must take exactly these arguments:\n",
    "- function: Callable[np.ndarray], float] - the objective function to minimise.\n",
    "- bounds: list[tuple[float, float]] - a list of (lower, upper) pairs delimiting the search space for each dimension.\n",
    "- budget: int - the total number of objective-function evaluations the algorithm may perform.\n",
    "\n",
    "The function should return a tuple[float, np.ndarray] containing the best objective value found and the corresponding decision vector.\n",
    "\n",
    "Your solution should be wrapped in a Markdown Python code block.\n",
    "\n",
    "```python\n",
    "import numpy as np \n",
    "\n",
    "def new_metaheuristic(\n",
    "\tfunction: Callable[[np.ndarray], float], \n",
    "    bounds: list[tuple[float, float]], \n",
    "    budget: int\n",
    ") -> tuple[float, np.ndarray]:\n",
    "    ...\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(model=MODEL, contents=[PROMPT_METAHEURISTIC])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "Describe the metaâ€‘heuristic generated by Gemini. Does the idea make sense? Is it novel? What are its weaknesses? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaheuristic = FunctionParser.parse(response.text, \"new_metaheuristic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And quantify its quality (average across 10 runs for Rastrigin in 10D):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Callable, Generator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def rastrigin(x: np.ndarray) -> float:\n",
    "    A: float = 10.0\n",
    "    return float(A * len(x) + np.sum(x**2 - A * np.cos(2 * np.pi * x)))\n",
    "\n",
    "\n",
    "class OptimizerVerifier:\n",
    "    def __init__(\n",
    "        self,\n",
    "        budget: int = 10_000,\n",
    "        dims: int = 10,\n",
    "        seeds_count: int = 10,\n",
    "        test_function: Callable = rastrigin,\n",
    "    ) -> None:\n",
    "        self.budget = budget\n",
    "        self.dims = dims\n",
    "        self.seeds_count = seeds_count\n",
    "        self.test_function = test_function\n",
    "\n",
    "    def verify(\n",
    "        self,\n",
    "        optimizer: Callable,\n",
    "    ) -> dict[str, float]:\n",
    "        bounds = [(-5, 5) for _ in range(self.dims)]\n",
    "        results = []\n",
    "        for seed in range(self.seeds_count):\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "            best_val, _ = optimizer(self.test_function, bounds, self.budget)\n",
    "            results.append(best_val)\n",
    "        return np.mean(best_val)\n",
    "\n",
    "\n",
    "verifier = OptimizerVerifier()\n",
    "mean_score_for_rastrigin = verifier.verify(metaheuristic)\n",
    "mean_score_for_rastrigin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go one step further. We can calculate the quality (fitness function) for each solution (metaheuristic) generated by LLM. In this case we can try to apply crossover/mutation operators to textual solutions. We can visualize it as optimization process in the space of Python functions that represent different optimization algorithms.\n",
    "\n",
    "### Exercise 2:\n",
    "Review [Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model](https://arxiv.org/pdf/2401.02051) and read **3.4 Prompt Strategies**. Re-implement one of the prompt strategies from **3.4 Prompt Strategies** of Evolution of Heuristics. Generate NÂ =Â 5 distinct algorithms, benchmark them and report the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run one of these operators, and try to explain what happened? Are the new mutated solution better than previous one? Calculate the quality of new solution and old ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "Implement Evolution of Heuristics (or at least part of it). Start simple (pseudocode):\n",
    "```\n",
    "current_population = [generate_heuristic()]\n",
    "for _ in range(10):\n",
    "   parents = current_population[-p:]\n",
    "   new_solution = E1(parents) # Read 3.4. Prompt Strategies to better understand E1\n",
    "   f_new_solution = verify(new_solution)\n",
    "   current_population.append(new_solution)\n",
    "```\n",
    "Save all solutions (best would be to have a separate file for each one). Analyse 5 different ones. Plot quality of solution per epoch. Is this iterative process converging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call to Action\n",
    "The GECCO 2025 conference is hosting a [competition](https://gecco-2025.sigevo.org/Competition?itemId=5104) on LLM-designed Evolutionary Algorithms. If youâ€™re interested in collaborating and participating as a team, feel free to send me a direct message. Letâ€™s explore the opportunity together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Recommended Reading\n",
    "- [AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms](https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/)\n",
    "- Shojaee, Parshin, et al. [LLM-SR: Scientific equation discovery via programming with large language models.](https://arxiv.org/abs/2404.18400)\n",
    "- Romera-Paredes, Bernardino, et al. [Mathematical discoveries from program search with large language models.](https://www.nature.com/articles/s41586-023-06924-6)\n",
    "- van Stein, Niki, and Thomas BÃ¤ck. [Llamea: A large language model evolutionary algorithm for automatically generating metaheuristics.](https://arxiv.org/abs/2405.20132)\n",
    "- Liu, Fei, et al. [Evolution of heuristics: Towards efficient automatic algorithm design using large language model.](https://arxiv.org/abs/2401.02051)\n",
    "- van Stein, Niki, et al. [BLADE: Benchmark suite for LLM-driven Automated Design and Evolution of iterative optimisation heuristics](https://arxiv.org/html/2504.20183v1)\n",
    "- [OpenEvolve](https://github.com/codelion/openevolve)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
